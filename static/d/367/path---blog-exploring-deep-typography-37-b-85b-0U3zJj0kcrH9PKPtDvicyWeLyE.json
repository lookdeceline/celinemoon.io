{"data":{"markdownRemark":{"html":"<h2>i. Motivation</h2>\n<p>My little brother writes his <a href=\"https://www.hohyeonmoon.com/\">developer's blog</a> in Korean. But often, he wrties certain terminologies in English.\nAn important part of a blog aesthetic is the font. While there are few hundreds of free English fonts, there aren't that many available in Korean.\nSo he had to spend hours finding the right Korean and English fonts that were available for free, but also look good enough together. </p>\n<p>Creating a new font is an absolute pita. Even more so for Asian characters that have more character numbers.\nKorean has 40 characters, and a Korean <em>word</em> is a combination of at least 2 characters.\nWith <a href=\"https://type.method.ac/\">kerning</a> included, the font design process requires hard manual work on each pixel. </p>\n<p>What if font styles could be transferred from one language to another? </p>\n<p>In search of <strong>a neural network that can properly create new fonts</strong>, this series will have three different posts: </p>\n<br/>\n<p><strong>1.  Naive approach</strong></p>\n<p>exploring font space with deep learning methods such as VGG16 and T-SNE. </p>\n<p><strong>2.  Advanced approach</strong></p>\n<p>exploring font space with deep learning methods such as autoencoder, VAE, and GAN.</p>\n<p><strong>3.  Future works</strong></p>\n<p>personal projects</p>\n<br/>\n<p>** <em>This post covers part 1. Parts 2, 3 are soon to be uploaded</em>.</p>\n<h2>Exploring font space using VGG16 &#x26; T-SNE</h2>\n<p>There have been two interesting projects that have attempted to :</p>\n<p><strong>i)</strong> visualize distribution of similar font types in clusters using VGG16 &#x26; T-SNE</p>\n<p><strong>ii)</strong> create new fonts by training T-SNE  </p>\n<h2>ii. Visualizing font space</h2>\n<p>Two separate projects - one by Kevin Ho, another by Jack Qiao - have wondefully visualized various fonts on a low dimensional (2D or 3D) space map.\nBoth projects leveraged VGG16 to extract feature vectors off font images. Then, both ran the extracted feature embeddings through T-SNE.</p>\n<br/>\n<p><em>disclosure: this part of the post has been inspired by Kevin Ho's <a href=\"https://medium.com/ideo-stories/organizing-the-world-of-fonts-with-ai-7d9e49ff2b25\">original post</a>\n&#x26; Jack Qiao's <a href=\"https://github.com/Jack000/fontjoy\">github repo</a>.</em></p>\n<h3>1) implementation steps</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 780px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/80b4d2dda823603db540765589c3d7bf/cc43b/post04-ideo-implementation.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 74.97500000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe9UNIP/xAAVEAEBAAAAAAAAAAAAAAAAAAAgQf/aAAgBAQABBQKn/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGRAAAgMBAAAAAAAAAAAAAAAAAREQICFR/9oACAEBAAE/ISSgWdotcf/aAAwDAQACAAMAAAAQcM//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAbEAEAAgIDAAAAAAAAAAAAAAABABEhQRAxUf/aAAgBAQABPxABGoz4l3yvEuCq1C6L73P/2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"ideo-implementation\"\n        title=\"ideo-implementation\"\n        src=\"/static/80b4d2dda823603db540765589c3d7bf/751b3/post04-ideo-implementation.jpg\"\n        srcset=\"/static/80b4d2dda823603db540765589c3d7bf/47425/post04-ideo-implementation.jpg 195w,\n/static/80b4d2dda823603db540765589c3d7bf/53d89/post04-ideo-implementation.jpg 390w,\n/static/80b4d2dda823603db540765589c3d7bf/751b3/post04-ideo-implementation.jpg 780w,\n/static/80b4d2dda823603db540765589c3d7bf/b2d4e/post04-ideo-implementation.jpg 1170w,\n/static/80b4d2dda823603db540765589c3d7bf/86a84/post04-ideo-implementation.jpg 1560w,\n/static/80b4d2dda823603db540765589c3d7bf/cc43b/post04-ideo-implementation.jpg 4000w\"\n        sizes=\"(max-width: 780px) 100vw, 780px\"\n      />\n  </a>\n    </span> </p>\n<ol>\n<li>Dataset:  Create a 'Handgloves' image for each font. (about 800 fonts in total, so that would make about 800 different 'Handgloves' images)</li>\n<li>Extract feature vector:  For each font image, run through VGG16 Convolutional Neural Network to get a feature embedding. </li>\n<li>Visualize:  Run all feature vectors through T-SNE to visualize their distributions over a 2-D plane. </li>\n</ol>\n<p>Visualization results can be viewed here:</p>\n<p><a href=\"http://fontmap.ideo.com/\">Kevin Ho (IDEO)</a></p>\n<p><a href=\"https://fontjoy.com/projector/\">Jack Qiao</a></p>\n<h3>2) applications</h3>\n<p>Both projects are applied to a design aid to help designers make easier font choice. Designers can look up IDEO's font map, or Jack Qiao's </p>\n<!-- \nseries into 3 parts - intro \n1. VGG\n2. feel the kern 무슨 nn?\n3. auto encoder\n4. vae, gan \n5. future 1 :  style transfer :  english fonts to korean  using cycle gan??? \n\tthen what is cycle gan ??? where is it used?\n\twhat other ways are there to trasfer style?\n6. future 2 : new fonts dataset -- only containing fonts with legit characters \n\t- google fonts\n\t- behance free fonts \n\t- ==> train with these fonts and see if the nn creates fonts that look like ones that arent free (ex. apercu)\n7. future 3:  \n-->","excerpt":"i. MotivationMy little brother writes his developer's blog in Korean. But often, he wrties certain terminologies in English. \nAn important part of a blog…","frontmatter":{"date":"03 January, 2020","path":"/blog/exploring-deep-typography","title":"Exploring Deep Typography"},"fields":{"readingTime":{"text":"3 min read"}}}},"pageContext":{"isCreatedByStatefulCreatePages":false}}
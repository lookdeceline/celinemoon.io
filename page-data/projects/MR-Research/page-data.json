{"componentChunkName":"component---src-templates-project-post-js","path":"/projects/MR-Research","result":{"data":{"markdownRemark":{"html":"<h3>About This Research</h3>\n<hr>\n<p>While I worked at Human-centered Computer Systems lab at Seoul National University as a research intern, I took a leading role in a Mixed Reality Research. Our team designed and implemented a novel Mixed Reality system that adaptively blends real-life objects into the virtual environment, thereby allowing users to freely perform daily tasks inside the virtual world.</p>\n<h3>Project Context</h3>\n<hr>\n<h4>What is Mixed Reality Research?</h4>\n<p>A novel Mixed Reality system with a smartphone-based AR headset to adaptively blend real-life objects into the virtual environment, such that a user can freely perform daily tasks inside the virtual world.</p>\n<div class=\"projectImage\" style=\"width:60%; margin: 30px auto;\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 2416px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/d5998f809b2ea607243325db93b8bdae/4f1b6/what-is-mr.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 40.599999999999994%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAQC/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQD/2gAMAwEAAhADEAAAAa9EwgP/xAAbEAACAQUAAAAAAAAAAAAAAAABAgMABBITFP/aAAgBAQABBQLGXfdK5PPI1f/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAECAQE/AUf/xAAbEAABBAMAAAAAAAAAAAAAAAAAAQIREjFCcf/aAAgBAQAGPwKdOjFblCan/8QAGhAAAgIDAAAAAAAAAAAAAAAAAAERMUFhcf/aAAgBAQABPyHcS6KURmJS7hn/2gAMAwEAAgADAAAAEIPf/8QAFhEBAQEAAAAAAAAAAAAAAAAAEQAh/9oACAEDAQE/EHWb/8QAFhEAAwAAAAAAAAAAAAAAAAAAARAh/9oACAECAQE/EDU//8QAGxAAAgMAAwAAAAAAAAAAAAAAAREAITFRYZH/2gAIAQEAAT8QYRAYgOBY1sGwwILQtbfU3N2gH7P/2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"what is mr\" title=\"what is mr\" src=\"/static/d5998f809b2ea607243325db93b8bdae/4f1b6/what-is-mr.jpg\" srcset=\"/static/d5998f809b2ea607243325db93b8bdae/451a4/what-is-mr.jpg 2000w,\n/static/d5998f809b2ea607243325db93b8bdae/4f1b6/what-is-mr.jpg 2416w\" sizes=\"(max-width: 2416px) 100vw, 2416px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n</div>\n<h4>Research Motivation</h4>\n<p>The research began with a single question:\nHow to make dull daily activities more delightful with Virtual Reality?</p>\n<div class=\"projectImage\" style=\"width:60%; margin: 30px auto;\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 2415px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/dc9ced54c0a1061379e3909187f592d3/84cd2/motivation.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 16.900000000000002%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAADABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAIF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB2qCQf//EABYQAQEBAAAAAAAAAAAAAAAAAAEAEf/aAAgBAQABBQIDcJv/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAVEAEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAQAGPwKP/8QAGRABAAIDAAAAAAAAAAAAAAAAAQARITFh/9oACAEBAAE/IRUFBonKCnE//9oADAMBAAIAAwAAABDzz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAQEAAwAAAAAAAAAAAAAAAAERABAh/9oACAEBAAE/EFgRAHA0AkITP//Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"motivation\" title=\"motivation\" src=\"/static/dc9ced54c0a1061379e3909187f592d3/84cd2/motivation.jpg\" srcset=\"/static/dc9ced54c0a1061379e3909187f592d3/451a4/motivation.jpg 2000w,\n/static/dc9ced54c0a1061379e3909187f592d3/84cd2/motivation.jpg 2415w\" sizes=\"(max-width: 2415px) 100vw, 2415px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n</div>\n<p>What if in a virtual world, we could still see and use the physical objects we use in reality?\nWhy don't we re-render the reality so that we selectively see what we need and the rest is replaced\nwith virtual world?</p>\n<h3>Challenge</h3>\n<hr>\n<p>The main design challenge lies in maintaining the right balance between immersion and utility.</p>\n<p>a.k.a. To Show Or Not To Show</p>\n<ul>\n<li><strong>immersion</strong> = how immersive is the virtual world experience?</li>\n<li><strong>utility</strong> = how easily can the user carry out daily tasks in the virtual world, such as sending an\nemail?</li>\n</ul>\n<h4>Key Insights To Balancing Between Utility and Immersion</h4>\n<p>Likewise, different objects have different need for utility or immersion, depending on how much\ndirectly the user intends to interact with the object.</p>\n<p>Not all objects in the virtual world should be virtually rendered.\n• E.g., the user's laptop should be rendered in its real physical appearance, , so that the user can send an email for\nreal, even in the virtual environment.</p>\n<p>Nonetheless, other objects / space should be virtually replaced for the sake of immersiveness of\nthe virtual environment.</p>\n<h4>The Utility-Immersion Spectrum</h4>\n<p>Thus, depending on the interaction property, we identified three different groups of the physical\nsurrounding, each requiring a different amount of utility vs amount of immersion. They can be\nvisualized on the spectrum of utility-immersion.</p>\n<div class=\"projectImage\" style=\"width:80%; margin: 30px auto;\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 2973px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/be51ded1d687e89fbf5acc2b75c082e0/2f455/spectrum.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 10.9%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAACABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAdwJAR//xAAZEAABBQAAAAAAAAAAAAAAAAABAAIQERL/2gAIAQEAAQUCoCMtX//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABgQAAIDAAAAAAAAAAAAAAAAAAABECEy/9oACAEBAAY/AqjKP//EABoQAAICAwAAAAAAAAAAAAAAAAABESFBwfH/2gAIAQEAAT8hoQSvAtnIP//aAAwDAQACAAMAAAAQB8//xAAVEQEBAAAAAAAAAAAAAAAAAAABEP/aAAgBAwEBPxBn/8QAFhEAAwAAAAAAAAAAAAAAAAAAARAx/9oACAECAQE/EDV//8QAGRABAAMBAQAAAAAAAAAAAAAAEQABMSHx/9oACAEBAAE/EAUVogZR3uZ5uf/Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"spectrum\" title=\"spectrum\" src=\"/static/be51ded1d687e89fbf5acc2b75c082e0/2f455/spectrum.jpg\" srcset=\"/static/be51ded1d687e89fbf5acc2b75c082e0/451a4/spectrum.jpg 2000w,\n/static/be51ded1d687e89fbf5acc2b75c082e0/2f455/spectrum.jpg 2973w\" sizes=\"(max-width: 2973px) 100vw, 2973px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n</div>\n<ul>\n<li><strong>direct-use</strong>\nreal objects that the user needs to use directly.\nFor this group of objects, the need for utility trumps the need for immersion,\nas the user requires fine-grained knowledge of the objects to directly use them. e.g., the user's\nlaptop</li>\n<li><strong>indirect-use</strong>\nreal objects that the user should be aware of in order to avoid bumping.\nFor this group of objects, the need for utility equals the need for immersion, as the user only\nrequires approximate knowledge (size, location) of the objects to indirectly interact with them.\ne.g., the user‘s desk</li>\n<li><strong>the rest</strong>\nphysical space that can be replaced with virtual scenaries.\nFor this group of phsical surrounding, the need for immersion trumps the need for utility. e.g.,\nempty space of the user‘s room</li>\n</ul>\n<h3>Design Choice, Technical Solution</h3>\n<hr>\n<div class=\"projectImage\" style=\"width:100%; margin: 30px auto;\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 5400px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/1477a1d07f42d17ee2bb541e25fa9fb2/0b860/solution.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 39.35%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAd2AsD//xAAVEAEBAAAAAAAAAAAAAAAAAAAAQf/aAAgBAQABBQJX/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAEP/aAAgBAQAGPwJ//8QAGRAAAgMBAAAAAAAAAAAAAAAAATEAECFB/9oACAEBAAE/IehwNpr/2gAMAwEAAgADAAAAEHPP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGxAAAgIDAQAAAAAAAAAAAAAAASEAETFBUZH/2gAIAQEAAT8Qo6K7cJXRQBYPs//Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"solution\" title=\"solution\" src=\"/static/1477a1d07f42d17ee2bb541e25fa9fb2/0b860/solution.jpg\" srcset=\"/static/1477a1d07f42d17ee2bb541e25fa9fb2/451a4/solution.jpg 2000w,\n/static/1477a1d07f42d17ee2bb541e25fa9fb2/120d2/solution.jpg 4000w,\n/static/1477a1d07f42d17ee2bb541e25fa9fb2/0b860/solution.jpg 5400w\" sizes=\"(max-width: 5400px) 100vw, 5400px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n</div>\n<h3>System Architecture</h3>\n<hr>\n<div class=\"projectImage\" style=\"width:100%; margin: 30px auto;\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 5532px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/2710c499aa0875e030b076924945d947/a3c96/sys-arch2.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 34.7%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAIEBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAdqQVwf/xAAZEAACAwEAAAAAAAAAAAAAAAABAgADEBH/2gAIAQEAAQUCD9wWOZ//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAYEAACAwAAAAAAAAAAAAAAAAAAEDEyof/aAAgBAQAGPwKFTT//xAAYEAADAQEAAAAAAAAAAAAAAAAAARExIf/aAAgBAQABPyFyvEFzKVudH//aAAwDAQACAAMAAAAQAA//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAwEBPxBX/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAERMf/aAAgBAgEBPxCMU//EABgQAQEBAQEAAAAAAAAAAAAAAAERIQBh/9oACAEBAAE/EGfVJrb7xDXC1vDY4jTvvf/Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"sys arch2\" title=\"sys arch2\" src=\"/static/2710c499aa0875e030b076924945d947/a3c96/sys-arch2.jpg\" srcset=\"/static/2710c499aa0875e030b076924945d947/451a4/sys-arch2.jpg 2000w,\n/static/2710c499aa0875e030b076924945d947/120d2/sys-arch2.jpg 4000w,\n/static/2710c499aa0875e030b076924945d947/a3c96/sys-arch2.jpg 5532w\" sizes=\"(max-width: 5532px) 100vw, 5532px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n</div>\n<h3>Final Output, Lessons</h3>\n<hr>\n<div class=\"projectImage\" style=\"width:60%; margin: 30px auto;\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 2134px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/96f7dcf7159000e78c17e7187c9c5f51/58498/output.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 107.14999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,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'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"output\" title=\"output\" src=\"/static/96f7dcf7159000e78c17e7187c9c5f51/58498/output.png\" srcset=\"/static/96f7dcf7159000e78c17e7187c9c5f51/f97d7/output.png 2000w,\n/static/96f7dcf7159000e78c17e7187c9c5f51/58498/output.png 2134w\" sizes=\"(max-width: 2134px) 100vw, 2134px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n</div>\n<h4>Final Output</h4>\n<p>The real world's physical surroundings are adaptively blended into the virtual world. Compare the images on the left (real world, shot by AR headset without our app) and images on the right (re-rendered reality, shot with our app). </p>\n<h4>Lessons</h4>\n<p>Despite working as an intern, I took a leading role as a lead investigator of this project, which consisted of multiple M.S. and Ph.D students. Putting various state-of-the-art technologies together to build a system that puts human-centered use cases at the heart was a valuable experience. </p>\n<p>To seamlessly integrate the real and virtual worlds, I incorporated various sensors (camera, LiDAR, IMU sensor) and applied different sensing technology (deep learning-based 3D object detection and simultaneous localization and mapping) into our system. The system efficiently contextualized users’ activity and their physical surroundings in real time.</p>\n<!-- <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/4SZl1r2O_bY\" frameborder=\"0\" allowfullscreen></iframe> -->","rawMarkdownBody":"\n### About This Research\n---\nWhile I worked at Human-centered Computer Systems lab at Seoul National University as a research intern, I took a leading role in a Mixed Reality Research. Our team designed and implemented a novel Mixed Reality system that adaptively blends real-life objects into the virtual environment, thereby allowing users to freely perform daily tasks inside the virtual world.\n\n\n### Project Context\n---\n#### What is Mixed Reality Research?\nA novel Mixed Reality system with a smartphone-based AR headset to adaptively blend real-life objects into the virtual environment, such that a user can freely perform daily tasks inside the virtual world.\n\n<div class=\"projectImage\" style=\"width:60%; margin: 30px auto;\">\n    <img src=\"./what-is-mr.jpg\">\n</div>\n\n\n#### Research Motivation\nThe research began with a single question:\nHow to make dull daily activities more delightful with Virtual Reality?\n\n\n<div class=\"projectImage\" style=\"width:60%; margin: 30px auto;\">\n    <img src=\"./motivation.jpg\">\n</div>\n\nWhat if in a virtual world, we could still see and use the physical objects we use in reality?\nWhy don't we re-render the reality so that we selectively see what we need and the rest is replaced \nwith virtual world?\n\n\n### Challenge\n---\nThe main design challenge lies in maintaining the right balance between immersion and utility.\n\na.k.a. To Show Or Not To Show\n\n* **immersion** = how immersive is the virtual world experience?\n* **utility** = how easily can the user carry out daily tasks in the virtual world, such as sending an \nemail?\n\n\n#### Key Insights To Balancing Between Utility and Immersion\n\nLikewise, different objects have different need for utility or immersion, depending on how much \ndirectly the user intends to interact with the object.\n\nNot all objects in the virtual world should be virtually rendered.\n• E.g., the user's laptop should be rendered in its real physical appearance, , so that the user can send an email for \nreal, even in the virtual environment.\n\nNonetheless, other objects / space should be virtually replaced for the sake of immersiveness of \nthe virtual environment.\n\n\n#### The Utility-Immersion Spectrum\n\nThus, depending on the interaction property, we identified three different groups of the physical \nsurrounding, each requiring a different amount of utility vs amount of immersion. They can be \nvisualized on the spectrum of utility-immersion.\n\n<div class=\"projectImage\" style=\"width:80%; margin: 30px auto;\">\n    <img src=\"./spectrum.jpg\">\n</div>\n\n* **direct-use**\nreal objects that the user needs to use directly.\nFor this group of objects, the need for utility trumps the need for immersion,\nas the user requires fine-grained knowledge of the objects to directly use them. e.g., the user's \nlaptop\n\n* **indirect-use**\nreal objects that the user should be aware of in order to avoid bumping.\nFor this group of objects, the need for utility equals the need for immersion, as the user only \nrequires approximate knowledge (size, location) of the objects to indirectly interact with them. \ne.g., the user‘s desk\n\n* **the rest**\nphysical space that can be replaced with virtual scenaries.\nFor this group of phsical surrounding, the need for immersion trumps the need for utility. e.g., \nempty space of the user‘s room\n\n### Design Choice, Technical Solution\n---\n<div class=\"projectImage\" style=\"width:100%; margin: 30px auto;\">\n    <img src=\"./solution.jpg\">\n</div>\n\n### System Architecture\n---\n<div class=\"projectImage\" style=\"width:100%; margin: 30px auto;\">\n    <img src=\"./sys-arch2.jpg\">\n</div>\n\n\n### Final Output, Lessons\n---\n<div class=\"projectImage\" style=\"width:60%; margin: 30px auto;\">\n    <img src=\"./output.png\">\n</div>\n\n#### Final Output\nThe real world's physical surroundings are adaptively blended into the virtual world. Compare the images on the left (real world, shot by AR headset without our app) and images on the right (re-rendered reality, shot with our app). \n\n#### Lessons\nDespite working as an intern, I took a leading role as a lead investigator of this project, which consisted of multiple M.S. and Ph.D students. Putting various state-of-the-art technologies together to build a system that puts human-centered use cases at the heart was a valuable experience. \n\nTo seamlessly integrate the real and virtual worlds, I incorporated various sensors (camera, LiDAR, IMU sensor) and applied different sensing technology (deep learning-based 3D object detection and simultaneous localization and mapping) into our system. The system efficiently contextualized users’ activity and their physical surroundings in real time.\n\n\n\n<!-- <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/4SZl1r2O_bY\" frameborder=\"0\" allowfullscreen></iframe> -->\n","frontmatter":{"title":"Life-Immersive MR Research","date":"21 September, 2020","intro":"HCI Research on Mixed Reality system that allows access to physical objects inside virtual environment.","featuredImage":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAACE4AAAhOAFFljFgAAADF0lEQVQozx2S+09TZxzGzy/GuRgzE82SLUEY/qLLzEwXgziMoK1WQyiXlaLxQluhVqxiCdRrDKJxSwwadXNWwKCIxrsmNRCj0W3GmIoToVTg3E9vnp5T/oLv41t+eN7n+/7yyfN835dLZrPQVA3K+zEkIy8h9NxH6tYw4g/+xZvhD3j2WsDTkRQeRlPofykhPBTH4Is4ht5O4sOUCjGRgpJKk5xMQdSSxCV0HbKswIjx6DnVju8WL8DFTi/Gn3fjv6dnMDJ8Fo8vBhB9cBrr1/2MsopSOGpsqNvWgPcTfB4CKZEgUVUhyApxWiYNUZJhfpLgctjAcRxK1hTjdocHd2q9OHT8HNa2X4DF3YmvVzpR/NNy/LiyEBX2Mvw/PgGRtRMUmXhJxLQosIRpFlWSoE8qcDo2Yd58DsWWhej7bT2wdhfk3YdYwgi6BqOo7n4N21Yb7M4i1HtsiI2PQVIUiLJEgiiAF3jiUhm2A1WBxoCHD7hRZ1+BZncJOh11mC4KAqUewOoCdjlhnvDjSJMVAU8J2vZUYWrsI7SEClVTSWUMhSXl9GwGyaQGmVdxJhSAy2ZBU80aWH+1o6KgDfsLQ/jjhw70Ffhw/ftKeMpL0GBfhXZ3LQSWMM0aZjIpYsrPxJlmlg1JiKKK463N2LH5F7S4ylG5hdX/thhzFxfiq0VFmPPNEhQstcDbUAVv9Woca9kKfiIGXc/AMHRimnUulzOQYcApXsLvR/ehcYsF+xtr4fMHsGHdRljLrCgvLWdegZO763Gv+what9twdG89puMxZBkwZxrENOtc/mCVaXKKp8MBN1WVLaMDe5speDBILX4/7dvTQv4mP3l3uul8h4+i10/Tta4AtTW56NPoCBmZJOVYspmciZk80DTyH1vGx/EYurtCCDZWIuRzIuipQWujAwfd1bPK30O+elw+2YqBq5dw52Y/+NG30DUROT2dhzGZxBnZzySzZ4++e0eRSIQGbgxQb7iHei+HqfevK9T75xXqY97/d5gGr4bp0cA1evXkLo39M0Ty6BtKC3Ey0gmaMbP5lPQFXS5zVPR5Fv4AAAAASUVORK5CYII=","aspectRatio":1.9047619047619047,"src":"/static/744975c509b721b17bab0c5cb50e4bb3/bc8e0/mr-sample.png","srcSet":"/static/744975c509b721b17bab0c5cb50e4bb3/8ac63/mr-sample.png 200w,\n/static/744975c509b721b17bab0c5cb50e4bb3/3891b/mr-sample.png 400w,\n/static/744975c509b721b17bab0c5cb50e4bb3/bc8e0/mr-sample.png 800w,\n/static/744975c509b721b17bab0c5cb50e4bb3/0f06f/mr-sample.png 921w","sizes":"(max-width: 800px) 100vw, 800px"}}},"backgroundColor":"#EFF5FA","tags":null,"type":"research","text":"HCI Research"}},"mdx":null},"pageContext":{"slug":"/projects/Mixed Reality Research/mixedRealityResearch/"}},"staticQueryHashes":["3159585216","3159585216"]}